{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaithrashagu/Internship/blob/master/Sentimental%20analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_OKPgD7eVAv",
        "colab_type": "text"
      },
      "source": [
        "# **Sentimental Analysis: Movie Review Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJvrwveIeuyM",
        "colab_type": "text"
      },
      "source": [
        "**What is sentimental analysis?**\n",
        "\n",
        ">      Sentimental Analysis is the automated process of understanding the opinion about a given subject from a written or spoken language.\n",
        "\n",
        "> **Usage of sentimental analysis**\n",
        "\n",
        "1.   Product Reviews\n",
        "2.   Movie Reviews\n",
        "3.   Food Reviews\n",
        "4.   Agricultural Reviews\n",
        "\n",
        "**INTRODUCTION:**\n",
        "\n",
        "> Our  analysis helps concerned organization to find opinions of people about movies from their reviews, if it is Positive, Negative or Netrual.\n",
        "\n",
        "> Our goal is to calculate the polarity of sentences that we extract  from the text of reviews.\n",
        "\n",
        "> We use the Internet Movies Database(IMDB) movie review datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5TLLF9mzHWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXLlmP4lzPMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_train = []\n",
        "for line in open('full_train.txt', 'r', encoding = \"utf8\"):\n",
        "    \n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open('full_test.txt', 'r', encoding = \"utf8\"):\n",
        "    \n",
        "    reviews_test.append(line.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUOtjhl9X0EJ",
        "colab_type": "code",
        "outputId": "2a21d113-4378-425f-8a7d-c6e9ab5f4ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "reviews_test[2]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As a recreational golfer with some knowledge of the sport\\'s history, I was pleased with Disney\\'s sensitivity to the issues of class in golf in the early twentieth century. The movie depicted well the psychological battles that Harry Vardon fought within himself, from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in English golf society. Likewise, the young Ouimet goes through his own class struggles, being a mere caddie in the eyes of the upper crust Americans who scoff at his attempts to rise above his standing. <br /><br />What I loved best, however, is how this theme of class is manifested in the characters of Ouimet\\'s parents. His father is a working-class drone who sees the value of hard work but is intimidated by the upper class; his mother, however, recognizes her son\\'s talent and desire and encourages him to pursue his dream of competing against those who think he is inferior.<br /><br />Finally, the golf scenes are well photographed. Although the course used in the movie was not the actual site of the historical tournament, the little liberties taken by Disney do not detract from the beauty of the film. There\\'s one little Disney moment at the pool table; otherwise, the viewer does not really think Disney. The ending, as in \"Miracle,\" is not some Disney creation, but one that only human history could have written.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1dOPaFR02M7",
        "colab_type": "code",
        "outputId": "b27ed81c-187e-41d9-bc5c-967a8e6f777f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "reviews_train[5]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kos6XvJ28UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "NO_SPACE = \"\"\n",
        "SPACE = \" \"\n",
        "\n",
        "def preprocess_reviews(reviews):\n",
        "    \n",
        "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiGG0Zqr3LbF",
        "colab_type": "code",
        "outputId": "b3d372f1-d7b3-47e1-8789-eab08df44815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "reviews_train_clean[5]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robins new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until williams character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all its worth a watch though its definitely not friday saturday night fare it rates a   from the fiend '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvTXLO9wYE-X",
        "colab_type": "code",
        "outputId": "4a3388f3-604a-467d-b281-7d809b17ec78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "reviews_test_clean[2]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'as a recreational golfer with some knowledge of the sports history i was pleased with disneys sensitivity to the issues of class in golf in the early twentieth century the movie depicted well the psychological battles that harry vardon fought within himself from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society likewise the young ouimet goes through his own class struggles being a mere caddie in the eyes of the upper crust americans who scoff at his attempts to rise above his standing  what i loved best however is how this theme of class is manifested in the characters of ouimets parents his father is a working class drone who sees the value of hard work but is intimidated by the upper class his mother however recognizes her sons talent and desire and encourages him to pursue his dream of competing against those who think he is inferior finally the golf scenes are well photographed although the course used in the movie was not the actual site of the historical tournament the little liberties taken by disney do not detract from the beauty of the film theres one little disney moment at the pool table otherwise the viewer does not really think disney the ending as in miracle is not some disney creation but one that only human history could have written'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6hMd5fX3Rgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(reviews_train_clean)\n",
        "X = cv.transform(reviews_train_clean)\n",
        "X_test = cv.transform(reviews_test_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrQXnypS3bs8",
        "colab_type": "code",
        "outputId": "e4e53b6f-24bd-4c6d-c2e9-74be372ec25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.87792\n",
            "Accuracy for C=0.05: 0.88624\n",
            "Accuracy for C=0.25: 0.8848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.88224\n",
            "Accuracy for C=1: 0.87936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO-gZZiY3jpb",
        "colab_type": "code",
        "outputId": "2ce6b22b-be4e-4864-e5d0-c67120a42337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "final_model = LogisticRegression(C=0.05)\n",
        "final_model.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_model.predict(X_test)))\n",
        "# Final Accuracy: 0.88128"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.88144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m22XCBml3_8p",
        "colab_type": "code",
        "outputId": "a44f6b07-bf7e-43e2-ee31-685267b4d909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        cv.get_feature_names(), final_model.coef_[0]\n",
        "    )\n",
        "}\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "    \n",
        "#     ('excellent', 0.9288812418118644)\n",
        "#     ('perfect', 0.7934641227980576)\n",
        "#     ('great', 0.675040909917553)\n",
        "#     ('amazing', 0.6160398142631545)\n",
        "#     ('superb', 0.6063967799425831)\n",
        "    \n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)\n",
        "    \n",
        "#     ('worst', -1.367978497228895)\n",
        "#     ('waste', -1.1684451288279047)\n",
        "#     ('awful', -1.0277001734353677)\n",
        "#     ('poorly', -0.8748317895742782)\n",
        "#     ('boring', -0.8587249740682945)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('excellent', 0.9283544357387583)\n",
            "('perfect', 0.7944277750867349)\n",
            "('great', 0.6745552873944645)\n",
            "('amazing', 0.6164834551994242)\n",
            "('superb', 0.6055919705160007)\n",
            "('worst', -1.367989768332016)\n",
            "('waste', -1.1688808937647217)\n",
            "('awful', -1.0273337505628393)\n",
            "('poorly', -0.8748022407884607)\n",
            "('boring', -0.8591221171268896)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfWz7KSN4jyq",
        "colab_type": "text"
      },
      "source": [
        "# Steaming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8mm2aXO42QU",
        "colab_type": "code",
        "outputId": "d14a32c0-5fe0-4682-8ef2-1576a1cb6df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "def get_stemmed_text(corpus):\n",
        "    from nltk.stem.porter import PorterStemmer\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
        "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(stemmed_reviews_train)\n",
        "X = cv.transform(stemmed_reviews_train)\n",
        "X_test = cv.transform(stemmed_reviews_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "    \n",
        "final_stemmed = LogisticRegression(C=0.05)\n",
        "final_stemmed.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_stemmed.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.87584\n",
            "Accuracy for C=0.05: 0.88224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.25: 0.8784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.87632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=1: 0.87344\n",
            "Final Accuracy: 0.87708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIVKYrmO71N2",
        "colab_type": "text"
      },
      "source": [
        "# Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52pzOLuK74Tv",
        "colab_type": "code",
        "outputId": "a100ca79-d75e-4e5d-ac3b-f64f9b0ecee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_lemmatized_text(corpus):\n",
        "    \n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
        "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(lemmatized_reviews_train)\n",
        "X = cv.transform(lemmatized_reviews_train)\n",
        "X_test = cv.transform(lemmatized_reviews_test)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "    \n",
        "final_lemmatized = LogisticRegression(C=0.25)\n",
        "final_lemmatized.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_lemmatized.predict(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Accuracy for C=0.01: 0.8696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.05: 0.88144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.25: 0.87728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.87584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=1: 0.87536\n",
            "Final Accuracy: 0.87364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agm5plbL86yW",
        "colab_type": "text"
      },
      "source": [
        "# n-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjPuTnT79AbU",
        "colab_type": "code",
        "outputId": "7f6d5846-5e63-405d-c20f-fc09eb3c7bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "    \n",
        "# Accuracy for C=0.01: 0.88416\n",
        "# Accuracy for C=0.05: 0.892\n",
        "# Accuracy for C=0.25: 0.89424\n",
        "# Accuracy for C=0.5: 0.89456\n",
        "# Accuracy for C=1: 0.8944\n",
        "    \n",
        "final_ngram = LogisticRegression(C=0.5)\n",
        "final_ngram.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_ngram.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.898\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.88032\n",
            "Accuracy for C=0.05: 0.88864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.25: 0.88992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.88944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=1: 0.88944\n",
            "Final Accuracy: 0.89868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUhpBwBF_Qyx",
        "colab_type": "text"
      },
      "source": [
        "#TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbfNHBWE_V9I",
        "colab_type": "code",
        "outputId": "c020c132-f19b-4dbe-9285-a820c6b34271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.01: 0.79632\n",
        "# Accuracy for C=0.05: 0.83168\n",
        "# Accuracy for C=0.25: 0.86768\n",
        "# Accuracy for C=0.5: 0.8736\n",
        "# Accuracy for C=1: 0.88432\n",
        "    \n",
        "final_tfidf = LogisticRegression(C=1)\n",
        "final_tfidf.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_tfidf.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.882\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.80208\n",
            "Accuracy for C=0.05: 0.83232\n",
            "Accuracy for C=0.25: 0.872\n",
            "Accuracy for C=0.5: 0.884\n",
            "Accuracy for C=1: 0.89248\n",
            "Final Accuracy: 0.88248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHDiS3VbAi5D",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NgKtR2pAsyW",
        "colab_type": "code",
        "outputId": "515ec52b-f1f9-4ce0-a432-d54458021bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
        "    \n",
        "# Accuracy for C=0.01: 0.89104\n",
        "# Accuracy for C=0.05: 0.88736\n",
        "# Accuracy for C=0.25: 0.8856\n",
        "# Accuracy for C=0.5: 0.88608\n",
        "# Accuracy for C=1: 0.88592\n",
        "    \n",
        "final_svm_ngram = LinearSVC(C=0.01)\n",
        "final_svm_ngram.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_svm_ngram.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.8974\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.8912\n",
            "Accuracy for C=0.05: 0.88864\n",
            "Accuracy for C=0.25: 0.88528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.5: 0.88464\n",
            "Accuracy for C=1: 0.88432\n",
            "Final Accuracy: 0.8976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iJ7J1RUDElx",
        "colab_type": "text"
      },
      "source": [
        "# Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM0kQFNbDVGk",
        "colab_type": "code",
        "outputId": "0082a52d-5ff4-485b-a60a-962323c91e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
        "    \n",
        "    svm = LinearSVC(C=c)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
        "    \n",
        "# Accuracy for C=0.001: 0.88784\n",
        "# Accuracy for C=0.005: 0.89456\n",
        "# Accuracy for C=0.01: 0.89376\n",
        "# Accuracy for C=0.05: 0.89264\n",
        "# Accuracy for C=0.1: 0.8928\n",
        "    \n",
        "final = LinearSVC(C=0.01)\n",
        "final.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.90064\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.001: 0.89312\n",
            "Accuracy for C=0.005: 0.90048\n",
            "Accuracy for C=0.01: 0.90064\n",
            "Accuracy for C=0.05: 0.89968\n",
            "Accuracy for C=0.1: 0.89984\n",
            "Final Accuracy: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh4ab8MnEk6L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Top Postitive and Negative Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3RaRJxEjXP",
        "colab_type": "code",
        "outputId": "acbe0501-cfb8-41f6-d617-02de8e751ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
        "    )\n",
        "}\n",
        "\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:30]:\n",
        "    print (best_positive)\n",
        "    \n",
        "print(\"\\n\\n\")\n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:30]:\n",
        "    print (best_negative)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('excellent', 0.23047713767955086)\n",
            "('perfect', 0.1850702597482869)\n",
            "('great', 0.17881801714679765)\n",
            "('wonderful', 0.16078926028434945)\n",
            "('amazing', 0.1522694986096792)\n",
            "('superb', 0.14695922648504361)\n",
            "('enjoyable', 0.14431473176657444)\n",
            "('best', 0.13064242610075727)\n",
            "('enjoyed', 0.12732762206948503)\n",
            "('fun', 0.1267172419778384)\n",
            "('today', 0.12183576670402631)\n",
            "('brilliant', 0.12065189650590906)\n",
            "('must see', 0.11754736622170905)\n",
            "('fantastic', 0.11538151112697591)\n",
            "('loved', 0.1133410113149595)\n",
            "('liked', 0.11200562608513458)\n",
            "('funniest', 0.11168721525195359)\n",
            "('incredible', 0.10863100559471513)\n",
            "('wonderfully', 0.10755457518068993)\n",
            "('better than', 0.10678236586352018)\n",
            "('rare', 0.10401813820902821)\n",
            "('beautiful', 0.10363770613904456)\n",
            "('bit', 0.101925268826305)\n",
            "('love', 0.10181872431531144)\n",
            "('well worth', 0.10117934757635975)\n",
            "('highly', 0.10095356164962363)\n",
            "('job', 0.10068802386224993)\n",
            "('watch it', 0.09981111969675736)\n",
            "('recommended', 0.0981496219093376)\n",
            "('moving', 0.09695427075133396)\n",
            "\n",
            "\n",
            "\n",
            "('worst', -0.3595863554314274)\n",
            "('awful', -0.25540100048057535)\n",
            "('boring', -0.2404542431122426)\n",
            "('waste', -0.23777958608398125)\n",
            "('bad', -0.22229431804666866)\n",
            "('poor', -0.20207930959522233)\n",
            "('terrible', -0.19911692713931942)\n",
            "('dull', -0.18248451681786848)\n",
            "('disappointment', -0.1757562635640689)\n",
            "('poorly', -0.17370340743035198)\n",
            "('disappointing', -0.1678067194767637)\n",
            "('unfortunately', -0.15749774722745383)\n",
            "('stupid', -0.15416425013476256)\n",
            "('horrible', -0.15405101274642094)\n",
            "('worse', -0.15304179975347135)\n",
            "('mess', -0.1479475727177633)\n",
            "('nothing', -0.14007350552709627)\n",
            "('lame', -0.13806269538755297)\n",
            "('save', -0.13592458293188273)\n",
            "('lacks', -0.13560833562608263)\n",
            "('oh', -0.1324413837264935)\n",
            "('avoid', -0.1317822408498097)\n",
            "('ridiculous', -0.13161464045497015)\n",
            "('weak', -0.1280039556228763)\n",
            "('annoying', -0.12648217933636133)\n",
            "('fails', -0.12462870803525625)\n",
            "('badly', -0.12273300621024008)\n",
            "('script', -0.12270962278583371)\n",
            "('not good', -0.12008064790274804)\n",
            "('not worth', -0.11956611613995911)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}